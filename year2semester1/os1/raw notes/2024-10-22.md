---
created: "2024-10-22"
done ?: "- [ ]"
---
# scheduling tradizionale di UNIX
lo scheduling di UNIX combina priorità e round-robin
- il quanto di tempo dura 1s
- esistono quindi diverse code, per gestire la priorità, e all’interno di ciasuna si fa round-robin
- le priorità vengono ricalcolate ogni secondo, e più un processo resta in esecuzione, più viene spinto in coda a minore priorità (feedback)
le priorità iniziali sono basate sul tipo di processo:
0. swapper (alta) (gestisce la memoria virtuale)
1. controllo di un dispositivo I/O a blocchi
2. gestione di file
3. controllo di un dispositivo di I/O a caratteri (tastiera o monitor vecchi (?))
4. processi utente (bassa)
## formula di scheduling
$$CPU_{j}(i)= \frac{CPU_{j}(i-1)}{2}$$
$$P_{j}(i)=Base_{j}+ \frac{CPU_{j}(i)}{2} + nice_{j}$$
- $CPU_{j}$ è una misura di quanto il processo $j$ ha usato il processore nell’intervallo $i$, con exponential averaging dei tempi passati $(\alpha = \frac{1}{2})$
	- per i running, $CPU_{j}$ viene incrementato di 1 ogni $\frac{1}{60}$ di secondo
- $Base_{j}$ è la priorità iniziale del processo
- $nice_{j}$ può essere usato dal processo stesso per “autodeclassarsi” come avente bassa priorità (lo usa il sistema per declassare processi che sa essere di minore importanza)
>[!example]
![[Pasted image 20241022092933.png]]
durante ogni quanto: il CPU count del processo in esecuzione viene aumentato di 1 ogni sessantesimo di secondo
a fine quanto: vengono ricalcolate tutte le priorità ($P_{j}(i)$), usando i valori aggionrati di $CPU_{j}(i)$
# architetture multiprocessore
le politiche di scheduling viste in precedenza valgono solo per sistemi con un solo processore. con sitemi multiprocessore (la norma, al giorno d’oggi)
- cluster
	- ogni processore ha la sua RAM, connessione con rete locale superveloce (?)
- processori specializzati
	- ad esempio, ogni I/O device ha un suo processore
- multi-processore e/o multi-core
	- condividono la RAM
	- un solo SO controlla tutto
## scheduler su architetture multiprocessore
avendo più processori/core, bisogna gestire il modo in cui si assegnano i processi ai rispettivi processori. ciò si può fare in due modi:
### assegnamento statico
quando un processo viene creato, gli viene assegnato un processore, e per tutta la sua durata quel processo andrà in esecuzione su quel processore
- in questo modo, si può usare uno scheduler per ogni processore
- vantaggi: semplice da realizzare, poco overhead
- svantaggi: un processore può rimanere idle
### assegnamento dinamico
per migliorare lo svantaggio dello statico, un processo, durante il suo corso di vita, potrà essere eseguito su diversi processori
- più complicato da realizzare
#### gestione del SO
ciò potrebbe andare bene per i processi utente, ma è meglio gestire diversamente i processi del SO
- il SO viene eseguito su un processore fisso
	- più semplice, ma può diventare bottleneck (se il processore è più lento degli altri)
	- anche se il sistema potrebbe funzionare con una failure di un processore, se il processore che fallisce è quello che gestisce il SO, cade tutto
- il SO viene eseguito sul processore che capita
	-  per quanto più flessibile, richiede più overhead per gestire il SO
# scheduling in Linux
cambia “molto spesso”
Linux cerca la velocità di esecuzione, attraverso la semplicità di implementazione: per questo motivo non esistono ne **long-term scheduler** nè **medium-term scheduler**
- in verità un embrione di long-term scheduler esiste, e gestisce il caso limite in cui, alla creazione del processo, non c’è memoria(neanche virtuale) libera per la creazione di esso
anche linux usa le priorità, ed esitono 2 gruppi di code:
## runqueues
## waitqueues
lo scheduling di Linux è q